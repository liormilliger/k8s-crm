minikube start -p logginig-stack


Step 1 - Deploy Elasticsearch

helm repo add bitnami https://charts.bitnami.com/bitnami

helm install elasticsearch bitnami/elasticsearch

Step 2 - Deploy Kibana

helm install kibana bitnami/kibana \
  --set elasticsearch.enabled=false \
  --set 'elasticsearch.external.hosts[0]=elasticsearch' \
  --set elasticsearch.external.port=9200 \
  --set service.type=LoadBalancer
*************************
Step 3 - Deploy Fluentd

vim /tmp/elasticsearch-output.yaml
------------------------
apiVersion: v1
kind: ConfigMap
metadata:
  name: elasticsearch-output
data:
  fluentd.conf: |

    # Ignore fluentd own events
    <match fluent.**>
      @type null
    </match>

    # TCP input to receive logs from the forwarders
    <source>
      @type forward
      bind 0.0.0.0
      port 24224
    </source>

    # HTTP input for the liveness and readiness probes
    <source>
      @type http
      bind 0.0.0.0
      port 9880
    </source>

    # Throw the healthcheck to the standard output instead of forwarding it
    <match fluentd.healthcheck>
      @type stdout
    </match>

    # Send the logs to the standard output
    <match **>
      @type elasticsearch
      include_tag_key true
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV['ELASTICSEARCH_PORT']}"
      logstash_format true
      <buffer>
        @type file
        path /opt/bitnami/fluentd/logs/buffers/logs.buffer
        flush_thread_count 2
        flush_interval 5s
      </buffer>
    </match>

vim /tmp/apache-log-parser.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  name: apache-log-parser
data:
  fluentd.conf: |

    # Ignore fluentd own events
    <match fluent.**>
      @type null
    </match>

    # HTTP input for the liveness and readiness probes
    <source>
      @type http
      port 9880
    </source>

    # Throw the healthcheck to the standard output instead of forwarding it
    <match fluentd.healthcheck>
      @type stdout
    </match>

    # Get the logs from the containers running in the cluster
    # This block parses logs using an expression valid for the Apache log format
    # Update this depending on your application log format
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /opt/bitnami/fluentd/logs/buffers/fluentd-docker.pos
      tag www.log
      <parse>
        @type regexp
        expression /^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \[(?<time>[^\]]*)\] \\"(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?\\" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$/
        time_format %d/%b/%Y:%H:%M:%S %z
      </parse>
    </source>

    # Forward all logs to the aggregators
    <match **>
      @type forward
      <server>
        host fluentd-0.fluentd-headless.default.svc.cluster.local
        port 24224
      </server>

      <buffer>
        @type file
        path /opt/bitnami/fluentd/logs/buffers/logs.buffer
        flush_thread_count 2
        flush_interval 5s
      </buffer>
    </match>


 kubectl apply -f /tmp/elasticsearch-output.yaml\n
 
 kubectl apply -f /tmp/apache-log-parser.yaml\n
 
 helm install fluentd bitnami/fluentd \
  --set aggregator.configMap=elasticsearch-output \
  --set forwarder.configMap=apache-log-parser \
  --set 'aggregator.extraEnv[0].name=ELASTICSEARCH_HOST' \
  --set 'aggregator.extraEnv[0].value=ELASTICSEARCH-COORDINATING-NODE-NAME' \
  --set 'aggregator.extraEnv[1].name=ELASTICSEARCH_PORT'
  --set 'string aggregator.extraEnv[1].value=9200' \
  --set 'forwarder.extraEnv[0].name=FLUENTD_DAEMON_USER' \
  --set 'forwarder.extraEnv[0].value=root' \
  --set 'forwarder.extraEnv[1].name=FLUENTD_DAEMON_GROUP' \
  --set 'forwarder.extraEnv[1].value=root'



